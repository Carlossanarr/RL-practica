import gymnasium as gym
import ale_py
from stable_baselines3 import DQN
from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack, VecTransposeImage
from safety_utils import PacmanSafetyMonitor 
import numpy as np
import pandas as pd
import time
import os

# Registrar entornos de Atari
gym.register_envs(ale_py)

# =========================================================
# ‚öôÔ∏è CONFIGURACI√ìN DEL EXAMEN
# =========================================================
# Aseg√∫rate de poner el nombre EXACTO del archivo .zip que gener√≥ el entrenamiento (SIN la extensi√≥n .zip)
MODELO_A_CARGAR = "dqn_pacman_IA_Sola_ShieldON_Penalty_steps10000" 
CARPETA_MODELOS = "agentes_entrenados" # <--- Carpeta donde est√°n los modelos entrenados
NUM_EPISODIOS   = 5                # Episodios para sacar la media
USAR_SHIELD     = True             # ¬øValidamos CON o SIN la ayuda del escudo?
RENDERIZAR      = False            # True para ver jugar a la IA
CARPETA_SALIDA  = "validacion"     # Nombre de la carpeta para guardar resultados
# =========================================================

env_id = "ALE/MsPacman-v5"

# --- DEFINICI√ìN DE WRAPPERS (Copiados y adaptados para Validaci√≥n) ---

class AddChannelDimWrapper(gym.ObservationWrapper):
    """Convierte (84, 84) -> (84, 84, 1). Necesario para DQN."""
    def __init__(self, env):
        super().__init__(env)
        if len(self.observation_space.shape) == 2:
            h, w = self.observation_space.shape
            self.observation_space = gym.spaces.Box(low=0, high=255, shape=(h, w, 1), dtype=np.uint8)
    
    def observation(self, obs):
        if len(obs.shape) == 2:
            return np.expand_dims(obs, axis=-1)
        return obs

class SafeShieldWrapper(gym.Wrapper):
    """
    Versi√≥n del Escudo espec√≠fica para VALIDACI√ìN.
    A√±ade 'safe_interventions' al diccionario 'info' para poder contar las intervenciones.
    """
    def __init__(self, env):
        super().__init__(env)
        self.monitor = PacmanSafetyMonitor()
        self.episode_interventions = 0 # Contador por episodio
        
    def reset(self, **kwargs):
        self.episode_interventions = 0
        return self.env.reset(**kwargs)
        
    def step(self, action):
        pacman_pos, ghosts_pos = self.monitor.get_positions(self.env)
        is_unsafe, dist = self.monitor.is_danger(pacman_pos, ghosts_pos, threshold=25)
        
        final_action = action
        
        if is_unsafe:
            safe_action = self.monitor.get_safe_action(pacman_pos, ghosts_pos)
            final_action = safe_action
            self.episode_interventions += 1
            
        obs, reward, terminated, truncated, info = self.env.step(final_action)
        
        # --- CLAVE: Inyectamos el dato para que el script de validaci√≥n lo lea ---
        info['safe_interventions'] = self.episode_interventions
        
        return obs, reward, terminated, truncated, info

# ---------------------------------------------------------
# CONSTRUCCI√ìN DEL ENTORNO
# ---------------------------------------------------------
def crear_entorno_validacion():
    # render_mode=None para ir r√°pido, "human" para ver
    modo = "human" if RENDERIZAR else None
    env = gym.make(env_id, frameskip=1, render_mode=modo)
    
    # Preprocesamiento IGUAL que en entrenamiento
    env = gym.wrappers.AtariPreprocessing(env, noop_max=0, frame_skip=4, screen_size=84, terminal_on_life_loss=False, grayscale_obs=True)
    env = AddChannelDimWrapper(env)
    
    # Activamos el escudo solo si la configuraci√≥n lo pide
    if USAR_SHIELD:
        env = SafeShieldWrapper(env)
    
    return env

# =========================================================
# EJECUCI√ìN DEL TEST
# =========================================================
if __name__ == "__main__":
    # Preparar entorno vectorizado
    val_env = DummyVecEnv([crear_entorno_validacion])
    val_env = VecFrameStack(val_env, n_stack=4)
    val_env = VecTransposeImage(val_env)

    # Construir ruta completa del modelo
    model_path = os.path.join(CARPETA_MODELOS, f"{MODELO_A_CARGAR}.zip")
    
    # --- BLOQUE DE DEPURACI√ìN DE RUTAS ---
    print("\nüîç --- DIAGN√ìSTICO DE RUTAS ---")
    print(f"üìç Directorio de trabajo actual (CWD): {os.getcwd()}")
    print(f"üìÇ Buscando archivo relativo: {model_path}")
    print(f"üó∫Ô∏è  Ruta absoluta calculada: {os.path.abspath(model_path)}")
    
    if not os.path.exists(model_path):
        print(f"\n‚ùå ERROR CR√çTICO: Python NO encuentra el archivo.")
        
        # Comprobar si al menos la carpeta existe
        if os.path.exists(CARPETA_MODELOS):
            print(f"‚úÖ La carpeta '{CARPETA_MODELOS}' S√ç existe. Contenido:")
            archivos = os.listdir(CARPETA_MODELOS)
            if not archivos:
                print("   (La carpeta est√° vac√≠a)")
            for f in archivos:
                print(f"   üìÑ {f}")
            print("\nüí° SUGERENCIA: Copia uno de los nombres de arriba (sin .zip) en 'MODELO_A_CARGAR'.")
        else:
            print(f"‚ùå La carpeta '{CARPETA_MODELOS}' NO existe en el directorio actual.")
            print("   Verifica que est√°s ejecutando el script desde la ra√≠z del proyecto.")
        
        exit()
    # -------------------------------------

    model = DQN.load(model_path)
    print("‚úÖ Modelo cargado correctamente.")

    # Crear carpeta de salida si no existe
    if not os.path.exists(CARPETA_SALIDA):
        os.makedirs(CARPETA_SALIDA)
        print(f"üìÅ Carpeta '{CARPETA_SALIDA}' creada (si no exist√≠a).")

    print(f"\nüöÄ Iniciando Validaci√≥n de {NUM_EPISODIOS} episodios...")
    print(f"üõ°Ô∏è Estado del Escudo: {'ACTIVADO' if USAR_SHIELD else 'DESACTIVADO (A pelo)'}")

    resultados = []

    try:
        for i in range(NUM_EPISODIOS):
            obs = val_env.reset()
            done = False
            total_reward = 0
            steps = 0
            intervenciones_finales = 0
            
            while not done:
                # PREDICCI√ìN DETERMINISTA (Sin exploraci√≥n aleatoria, la IA juega en serio)
                action, _ = model.predict(obs, deterministic=True)
                
                obs, reward, done, info = val_env.step(action)
                
                total_reward += reward
                steps += 1
                
                # Leemos las intervenciones desde el info que modificamos en el wrapper
                if USAR_SHIELD and 'safe_interventions' in info[0]:
                    intervenciones_finales = info[0]['safe_interventions']
                    
                # Control de velocidad para que lo veas bien si est√° renderizando
                if RENDERIZAR:
                    time.sleep(0.02) 

            print(f"   üîπ Episodio {i+1}: Puntos={total_reward[0]:.0f} | Intervenciones={intervenciones_finales}")
            
            resultados.append({
                "Episodio": i+1,
                "Recompensa": float(total_reward[0]),
                "Duracion": steps,
                "Intervenciones": intervenciones_finales,
                "Con_Escudo": USAR_SHIELD,
                "Modelo": MODELO_A_CARGAR
            })

    except KeyboardInterrupt:
        print("\nüõë Validaci√≥n detenida manualmente.")

    val_env.close()

    # Guardar y Mostrar Resumen
    if resultados:
        df = pd.DataFrame(resultados)
        print("\nüìä --- RESUMEN DE VALIDACI√ìN ---")
        print(f"Media de Puntos:      {df['Recompensa'].mean():.2f} +/- {df['Recompensa'].std():.2f}")
        print(f"Media de Intervenciones: {df['Intervenciones'].mean():.2f}")
        
        nombre_archivo = f"validacion_{MODELO_A_CARGAR}_shield{USAR_SHIELD}.csv"
        ruta_completa = os.path.join(CARPETA_SALIDA, nombre_archivo)
        
        df.to_csv(ruta_completa, index=False)
        print(f"üìù Resultados guardados en: {ruta_completa}")
    else:
        print("No se complet√≥ ning√∫n episodio.")