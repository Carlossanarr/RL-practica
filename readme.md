# Proyecto Pac-Man RL: DQN Seguro & H√≠brido

Este proyecto implementa un agente de Deep Q-Network (DQN) para jugar a Ms. Pac-Man utilizando la librer√≠a Stable Baselines 3.

Se diferencia de una implementaci√≥n est√°ndar por incluir t√©cnicas avanzadas de Seguridad (Safety RL) y Aprendizaje por Imitaci√≥n (Imitation Learning) para acelerar y asegurar el entrenamiento.

üöÄ Caracter√≠sticas Principales

- üéÆ Entrenamiento H√≠brido (Human-in-the-Loop):

    Permite al usuario jugar una fase inicial ("Warmup") para llenar la memoria de la IA con partidas de calidad.

    La IA aprende de tus movimientos antes de empezar a explorar por su cuenta.

- üõ°Ô∏è Escudo de Seguridad (Safety Shield):

    Un "Teacher" o supervisor monitoriza la distancia entre Pac-Man y los fantasmas.

    Intervenci√≥n: Si la IA va a cometer un error fatal, el escudo sobreescribe la acci√≥n para salvarla.

- üìâ Moldeado de Recompensa (Reward Shaping):

    Penalizaci√≥n por Peligro: Se puede configurar para castigar a la IA (-10 puntos) cada vez que entra en una zona de riesgo, independientemente de si el escudo la salva o no. Esto fomenta que aprenda a tener "miedo" por s√≠ misma.


- Instrucciones para ejecutar el Pac-Man Safe RL -

## Instalaci√≥n 

1. Clonar el repositorio

2.  Preparar el entorno virtual (recomendado)

```bash 
    conda create -n pacman_rl python=3.10
    conda activate pacman_rl
```
Instalar las librer√≠as necesarias:

```bash
pip install -r requirements.txt
```

3. Descargar los juegos de Atari 

``` bash 
autorom --accept-license
```
Este paso puede llevar un rato

## Configuraci√≥n

El comportamiento del entrenamiento se controla modificando las variables al inicio del archivo train_pacman.py:

```python
# ==========================================
# 0. CONFIGURACI√ìN
# ==========================================
USAR_IMITATION_WARMUP = True   # True: Juegas t√∫ primero. False: La IA entrena sola desde el principio.
PASOS_HUMANOS = 1000           # Cu√°ntos frames jugar√°s t√∫ (si la opci√≥n anterior es True).
PASOS_ENTRENAMIENTO = 10000    # Cu√°ntos pasos entrenar√° la IA aut√≥nomamente.

# --- CONFIGURACI√ìN DE SEGURIDAD ---
USAR_ESCUDO_IA = True          # True: El escudo corrige a la IA si est√° en peligro. False: La IA puede morir libremente.
PENALIZAR_PELIGRO = True       # True: Resta 10 puntos si los fantasmas est√°n cerca (ense√±a prudencia).

```

## Ejecuci√≥n

Ejecutar el script train_pacman.py para entrenar la configuraci√≥n de elegida:

``` bash
python train_pacman.py
```

Flujo de Ejecuci√≥n:

- Fase Humana (Si est√° activa): * Se abrir√° una ventana con el juego. Usa las FLECHAS DEL TECLADO para moverte.

**Nota**: Debes tener la terminal seleccionada/activa para que detecte las teclas.

Al terminar los pasos definidos, la ventana se cerrar√°.

- Fase de IA: La IA comenzar√° a entrenar a m√°xima velocidad (sin renderizado visual para ir r√°pido). Ver√°s una barra de progreso en la terminal.

- Finalizaci√≥n:

Se mostrar√°n estad√≠sticas de seguridad (cu√°ntas veces intervino el escudo o se penaliz√≥).

El modelo se guardar√° autom√°ticamente con un nombre descriptivo, por ejemplo:
dqn_pacman_Imitation_ShieldON_Penalty_steps10000.zip

## Validaci√≥n

Una vez entrando un agente, se puede utilizar el archivo validate_agent.py para calcular m√©tricas del agente:

``` bash
python validate_agent.py
```







